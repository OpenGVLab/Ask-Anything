# ğŸ¦œ VideoChat [[è®ºæ–‡](https://arxiv.org/abs/2305.06355)/[demo](https://vchat.opengvlab.com/)]

![images](assert/framework_cn.png)

æˆ‘ä»¬æå‡ºäº†VideoChatï¼Œä¸€ä¸ªä»¥èŠå¤©ä¸ºä¸­å¿ƒçš„è§†é¢‘ç†è§£ç³»ç»Ÿï¼Œå¼€å±•äº†æ¢ç´¢æ€§çš„è§†é¢‘ç†è§£ç ”ç©¶ã€‚
å®ƒé€šè¿‡ä¸€ä¸ªå¯å­¦ä¹ çš„æ¥å£å°†è§†é¢‘é¢„è®­ç»ƒæ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹ç»“åˆåœ¨ä¸€èµ·ï¼Œæ“…é•¿äºç©ºé—´-æ—¶é—´æ¨ç†ã€äº‹ä»¶å®šä½å’Œå› æœå…³ç³»æ¨æ–­ã€‚
ä¸ºäº†æœ‰æŒ‡å¯¼æ€§åœ°è®­ç»ƒè¿™ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè§†é¢‘ä¸ºä¸­å¿ƒçš„Instructionæ•°æ®é›†ï¼Œç”±æ•°åƒä¸ªè§†é¢‘å’Œè¯¦ç»†æè¿°åŠå¯¹è¯ç»„æˆã€‚
è¯¥æ•°æ®é›†å¼ºè°ƒç©ºé—´-æ—¶é—´æ¨ç†å’Œå› æœå…³ç³»ï¼Œä¸ºè®­ç»ƒä»¥èŠå¤©ä¸ºä¸­å¿ƒçš„è§†é¢‘ç†è§£ç³»ç»Ÿæä¾›äº†è®­ç»ƒæ•°æ®ã€‚
åˆæ­¥çš„å®éªŒå±•ç¤ºäº†æˆ‘ä»¬ç³»ç»Ÿåœ¨å¹¿æ³›çš„è§†é¢‘åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¥ æ›´æ–°
- **2023/11/29** VideoChat2å’ŒMVBenchå‘å¸ƒ:
  - [VideoChat2](./video_chat2/)æ˜¯åŸºäº[UMT](https://github.com/OpenGVLab/unmasked_teacher)å’Œ[Vicuna-v0](https://github.com/lm-sys/FastChat/blob/main/docs/vicuna_weights_version.md)æ„å»ºçš„å¼ºå¤§åŸºçº¿
  - **1.9M** å¤šæ ·[æŒ‡ä»¤æ•°æ®](./video_chat2/data.md)ä»¥ä¾¿æœ‰æ•ˆè°ƒä¼˜
  - [MVBench](./video_chat2/MVBench.md)æ˜¯ä¸€ä¸ªå…¨é¢çš„è§†é¢‘ç†è§£åŸºå‡†
- **2023/06/09**: å‘å¸ƒä»£ç å’Œè®­ç»ƒå¾®è°ƒè„šæœ¬:
    - ç›´æ¥è¿è¡Œ [scripts](./scripts)ï¼Œæ¯”å¦‚ `bash ./exp/run_7b_stage1.sh`.
    - ä½ å¯ä»¥è‡ªè¡Œä¿®æ”¹ `NNODE` æˆ–è€… `MASTER_NODE`ã€‚å¯¹äºç¬¬ä¸€é˜¶æ®µï¼Œè‡³å°‘éœ€è¦8ä¸ªGPUæ¥å¿«é€Ÿè®­ç»ƒã€‚å¯¹äºç¬¬äºŒé˜¶æ®µï¼Œ4ä¸ªGPUè¶³å¤Ÿã€‚
- **2023/05/12**: å‘å¸ƒ**7B**ç‰ˆæœ¬ï¼š
   - ğŸŠ [**æ¨¡å‹-7B**](https://drive.google.com/file/d/1C4s65TC5Zr85I8dZmnfrrw6oDAjj1H4P/view?usp=sharing)ï¼š7Bç‰ˆæœ¬éœ€è¦çº¦**20GBçš„GPUå†…å­˜**ï¼Œè€Œ13Bç‰ˆæœ¬éœ€è¦çº¦32GBçš„GPUå†…å­˜ã€‚
- **2023/05/11**: å‘å¸ƒ**ğŸ¦œVideoChat V1**ç‰ˆæœ¬ï¼Œå¯ä»¥**å¤„ç†å›¾åƒå’Œè§†é¢‘ç†è§£**ï¼
   - ğŸŠ [**æ¨¡å‹-13B**](https://drive.google.com/file/d/1BqmWHWCZBPkhTNWDAq0IfGpbkKLz9C0V/view?usp=share_link) and [**æ•°æ®**](https://github.com/OpenGVLab/InternVideo/tree/main/Data/instruction_data).
   - ğŸ¤— [**åœ¨çº¿æ¼”ç¤ºDemo**](https://vchat.opengvlab.com/)

## :hourglass_flowing_sand: è®¡åˆ’

- [x] å°è§„æ¨¡è§†é¢‘Instructionæ•°æ®å’Œè®­ç»ƒ
- [x] åœ¨BLIP+UniFormerV2+Vicunaä¸Šè¿›è¡Œè®­ç»ƒ
- [ ] å¤§è§„æ¨¡å’Œå¤æ‚çš„è§†é¢‘Instructionæ•°æ®
- [ ] åœ¨æ›´å¼ºè§†é¢‘åŸºç¡€æ¨¡å‹ä¸Šè¿›è¡ŒInstructionè®­ç»ƒ
- [ ] ä¸æ›´é•¿çš„è§†é¢‘è¿›è¡Œå‹å¥½çš„äº¤äº’
- [ ] â€¦

## :speech_balloon: ç¤ºä¾‹ [åœ¨çº¿ä½“éªŒğŸ¦œ](https://vchat.opengvlab.com/)

<div align="center">
<b>
  <font size="4">ä¸ChatGPTã€MiniGPT-4ã€LLaVAå’ŒmPLUG-Owlçš„æ¯”è¾ƒã€‚</font>
  <br>
  <font size="4" color="red">æˆ‘ä»¬çš„VideoChatå¯ä»¥è¾ƒå¥½åœ°å¤„ç†å›¾åƒå’Œè§†é¢‘ç†è§£ï¼</font>
</b>
</div>
<div align="center">
<img src="assert/comparison.png" width="90%">
</div>


<div align="center">
  <font size="4">
	<a href="https://pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com/papers/media/jesse_dance.mp4">[Video]</a> <b>ä¸ºä»€ä¹ˆè¿™ä¸ªè§†é¢‘å¾ˆæœ‰è¶£ï¼Ÿb>
  </font>
</div>
<div align="center">
<img src="assert/humor.png" width="50%">
</div>

<div align="center">
  <font size="4">
	<a href="https://pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com/papers/media/jp_dance.mp4">[Video]</a> <b>ç©ºé—´æ„ŸçŸ¥</b>
  </font>
</div>
<div align="center">
<img src="assert/spatial.png" width="50%">
</div>

<div align="center">
  <font size="4">
	<a href="https://pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com/papers/media/car_accident.mp4">[Video]</a> <b>æ—¶é—´æ„ŸçŸ¥</b>
  </font>
</div>
<div align="center">
<img src="assert/temporal.png" width="50%">
</div>

<div align="center">
  <font size="4">
	<a href="https://pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com/papers/media/idol_dancing.mp4">[Video]</a> <b>å¤šè½®å¯¹è¯</b>
  </font>
</div>
<div align="center">
<img src="assert/multi_turn.png" width="50%">
</div>

<div align="center">
  <font size="4">
	<b>å›¾åƒç†è§£</b>
  </font>
</div>
<div align="center">
<img src="assert/image.png" width="100%">
</div>
  
## :running: ä½¿ç”¨æ–¹æ³•

### Linux ç¯å¢ƒ
- å‡†å¤‡ç¯å¢ƒ.
  1) å»ºè®®åœ¨condaç¯å¢ƒä¸‹è¿›è¡Œå®‰è£… ï¼ˆå¯é€‰ï¼‰
  ```
  conda create -n videochat python=3.8
  conda activate videochat
  ```
  2) å®‰è£…pythonç¯å¢ƒ
    ```shell
    pip install -r requirements.txt
    ```
  3) ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹  
  
  - ä¸‹è½½[BLIP2](https://huggingface.co/docs/transformers/main/model_doc/blip-2) model:
    ```
    mkdir model
    wget -P ./model/ https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/eva_vit_g.pth 
    wget -P ./model/ https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xxl.pth
    ```
    - å¦‚æœæ‚¨ä¿®æ”¹äº†ä¸‹è½½çš„åœ°å€ï¼Œæ‚¨éœ€è¦ä¿®æ”¹ `vit_model_path` and `q_former_model_path` in [config.json](./configs/config.json) or [config_7b.json](./configs/config_7b.json).
    
  - ä¸‹è½½[StableVicuna](https://huggingface.co/CarperAI/stable-vicuna-13b-delta)æ¨¡å‹ï¼š
      -  æ‚¨éœ€è¦ä»[llama github](https://github.com/facebookresearch/llama) æˆ– [huggingface](https://huggingface.co/decapoda-research/llama-13b-hf) ä¸‹è½½é¢„è®­ç»ƒæƒé‡
      - **å¦‚æœæ‚¨æ˜¯ä»llama githubä¸­ä¸‹è½½çš„LLAMAï¼Œè¯·å…ˆå¯¹æƒé‡è¿›è¡Œé¢„å¤„ç†**
      ```shell
         # convert_llama_weights_to_hf is copied from transformers
          python src/transformers/models/llama/convert_llama_weights_to_hf.py \
          --input_dir /path/to/downloaded/llama/weights \
          --model_size 13B --output_dir /output/path
      ```
      - ä¸‹è½½13Bçš„ [stable-vicuna-13b-delta](https://huggingface.co/CarperAI/stable-vicuna-13b-delta)å¹¶å¤„ç†:
      ** è¯·æ³¨æ„ï¼Œè¿™å¯èƒ½éœ€è¦30Gä»¥ä¸Šçš„GPUæ˜¾å­˜ï¼Œå¦‚æœæ‚¨æœ‰24Gæ˜¾å­˜çš„GPUï¼Œè¯·ä¸‹è½½ä¸‹é¢çš„7Bæ¨¡å‹ **
      ```shell
      # fastchat v0.1.10
      python3 apply_delta.py \
        --base {llama-13bçš„æ¨¡å‹è·¯å¾„} \
        --target stable-vicuna-13b \
        --delta CarperAI/stable-vicuna-13b-delta
      ```
      - ä¸‹è½½7Bçš„ [vicuna-7b-delta-v0](https://huggingface.co/lmsys/vicuna-7b-delta-v0)å¹¶å¤„ç†ï¼š
        ```shell
        # fastchat v0.1.10
        python3 apply_delta.py \
          --base  {llama-7bçš„æ¨¡å‹è·¯å¾„} \
          --target vicuna-7b-v0 \
          --delta lmsys/vicuna-7b-delta-v0
        ```
        - Change the `llama_model_path` in [config.json](./configs/config.json) or [config_7b.json](./configs/config_7b.json).
  
      -  ä¸‹è½½[VideoChat-13B](https://drive.google.com/file/d/1BqmWHWCZBPkhTNWDAq0IfGpbkKLz9C0V/view?usp=share_link) or [VideoChat-7B](https://drive.google.com/file/d/1C4s65TC5Zr85I8dZmnfrrw6oDAjj1H4P/view?usp=sharing):
	
         - Change the `videochat_model_path` in [config.json](./configs/config.json)or [config_7b.json](./configs/config_7b.json).
        
    4) å¼€å§‹è¿è¡Œdemo
      ```shell
        python demo.py
	```
	
    5) æ‰“å¼€ 127.0.0.1:7860 å¼€å§‹ä½“éªŒ~
  
    6) [å¯é€‰] æˆ‘ä»¬ä¹Ÿæä¾›äº†Jupyter Notebook çš„demo
  
  # :page_facing_up: å¼•ç”¨

å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘å¼•ç”¨æˆ‘ä»¬ï¼š
```BibTeX
@article{2023videochat,
  title={VideoChat: Chat-Centric Video Understanding},
  author={KunChang Li, Yinan He, Yi Wang, Yizhuo Li, Wenhai Wang, Ping Luo, Yali Wang, Limin Wang, and Yu Qiao},
  journal={arXiv preprint arXiv:2305.06355},
  year={2023}
}
```
  
 # :thumbsup: è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºæ•°æ®:

[InternVideo](https://github.com/OpenGVLab/InternVideo), [UniFormerV2](https://github.com/OpenGVLab/UniFormerV2), [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4), [LLaVA](https://github.com/haotian-liu/LLaVA), [BLIP2](https://huggingface.co/docs/transformers/main/model_doc/blip-2), [StableLM](https://github.com/Stability-AI/StableLM).
  
